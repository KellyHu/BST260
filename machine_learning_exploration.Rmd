---
title: "machine_learning_exploration"
author: "Dongyuan Song"
date: "2018/12/5"
output:
  html_document:
    toc: true
    toc_float: true
    code_folding: hide
  github_document: default
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, 
                      #root.dir = "/n/irizarryfs01_backed_up/songdongyuan/PBM-Exploration/", 
                      root.dir = "D:/MS/Master Course/BST260/Final_project/BST260", 
                      fig.width = 8, fig.height = 6)
```

```{r}
library(tidyverse)
library(pROC)
library(caret)
library(pastecs)
library(ggcorrplot)
```

We first re-read in original data.
```{r}
dat <- read_csv("./data/food_coded_clean.csv", na = "nan")
```

```{r}
head(dat)
```

We notice that here is some duplicated columns. Filter out those columns.
```{r}
dat <- dat %>% dplyr::select( - ends_with("_1"))
```

```{r}
head(dat)
```

For `chr` column, we remove them. For `int` column we convert them all into `fct` (although some of them are nearly ordinary categorical data).
```{r}
weight_vector <- dat$weight
dat <- dat %>% dplyr::mutate_if(is.integer, as.factor) %>%
  dplyr::select_if(function(x) !is.character(x)) %>%
  dplyr::mutate(weight = as.numeric(weight_vector))
```


```{r}
head(dat)
```


```{r}
dat_dummy <- dummyVars(" ~ .", data = dat,  fullRank = TRUE)
dat_trsf <- data.frame(predict(dat_dummy, newdata = dat))
```

```{r}
nzv <- nearZeroVar(dat_trsf, saveMetrics= TRUE)
nzv[nzv$nzv,]
```
Unluckily, there are some near zero-variance factors. We remove them.

```{r}
nzv <- nearZeroVar(dat_trsf)
dat_trsf_nz <- dat_trsf[, -nzv]
```

Good.


Next we want to solve the correlation problem. We set the cutoff for high correlation as 0.9.
```{r}
descrCor <- cor(dat_trsf_nz, use = "pairwise.complete.obs")
summary(descrCor[upper.tri(descrCor)])

suppressWarnings(ggcorrplot(descrCor))
highlyCorDescr <- findCorrelation(descrCor, cutoff = .9)
dat_trsf_nz <- dat_trsf_nz[,-highlyCorDescr]
descrCor2 <- cor(dat_trsf_nz, use = "pairwise.complete.obs")
summary(descrCor2[upper.tri(descrCor2)])
```

```{r}
dim(dat)
dim(dat_trsf)
dim(dat_trsf_nz)
```



Imputation. Here we use medain imputation since it does not require centering.  
```{r}
preProcValues <- preProcess(dat_trsf_nz, method = c("medianImpute"), na.remove = TRUE)
dat_trsf_nz_im <- predict(preProcValues, dat_trsf_nz)
```

```{r}
dat_trsf_nz_im[1:10, 1:10]
```


```{r}
dat_trsf_nz_im %>% as.tibble() %>%
  ggplot(aes(x = GPA)) +
  geom_histogram() +
  theme_bw()
summary(dat_trsf_nz_im$GPA)
```

Split data into train set and test set.
```{r}
set.seed(1234)
trainIndex <- createDataPartition(dat_trsf_nz_im$GPA, p = .8, 
                                  list = FALSE, 
                                  times = 1)
head(trainIndex)
```


Now we can generate formal training set and test set.
```{r}
x.t <- dat_trsf_nz_im
y.t <- dat_trsf_nz_im[, "GPA"]
```

```{r}
y.train <- y.t[trainIndex]
y.test <- y.t[-trainIndex]

x.train <- x.t[trainIndex,]
x.test <- x.t[-trainIndex,]
```

```{r}
x <- x.train
y <- y.train
```

```{r}
stat.desc(y.train)
```


```{r, warning=TRUE}
set.seed(123)
models = c("knn","lm", "ridge", "lasso", "rf", "svmRadial", "glmboost", "xgbLinear", "nnet")
train.control = trainControl(method = "repeatedcv", number = 5, repeats = 10, verbose = FALSE)

n_models = length(models)
for (m in 1:n_models) {
    fit = train(GPA ~ ., method = models[m], trControl = train.control, data = x)
    print(c(models[m], getTrainPerf(fit)))
    pre = predict(fit, newdata = x.test, type = "raw")
    mse_test <- sqrt(mean((y.test - pre)^2))
    print(mse_test)
}
```

We also use the naive mean of traning set to calculate RMSE on test set.
```{r}
sqrt(mean((y.test - mean(y.train))^2))
```


Since the continous outcome might be difficult to predict, we might consider convert it into binary outcome. 
```{r}
dat_trsf_nz_im_c <- dat_trsf_nz_im %>% dplyr::mutate(GPA = GPA >= 3.5, GPA = as.factor(GPA))
x.c <- dat_trsf_nz_im_c
y.c <- dat_trsf_nz_im_c[, "GPA"]
```

```{r}
y.train.c <- y.c[trainIndex]
y.test.c <- y.c[-trainIndex]

x.train.c <- x.c[trainIndex,]
x.test.c <- x.c[-trainIndex,]
```

```{r}
x.c <- x.train.c
y.c <- y.train.c
```

```{r}
mean(as.numeric(y.train.c) - 1)
```

```{r}
set.seed(123)

models = c("knn", "rf", "glm", "lda",  "svmLinear", "svmRadial")
train.control = trainControl(method = "repeatedcv", number = 10, repeats = 10, verbose = FALSE)

n_models = length(models)

for (m in 1:n_models) {
    fit = train(GPA ~ ., method = models[m], trControl = train.control, data = x.c)
    print(c(models[m], getTrainPerf(fit)))
    pre = predict(fit, newdata = x.test.c, type = "raw")
    acc_test <- (mean(y.test.c == pre))
    print(acc_test)
}
```

We also calculate the baseline acc.
```{r}
(mean(y.test.c == TRUE))
```


Notice that SVM does not generate probability. Here we compare KNN and Random Forest.
```{r}
set.seed(123)
fit_knn <- train(GPA ~ ., method = "knn", trControl = train.control, data = x.c)
probs1 = predict(fit_knn, newdata = x.test.c, type = "prob")
R1 = roc(y.test.c, probs1[,2])
plot.roc(R1, col=1, lwd=2, main="ROC curves")
AUC1 = R1$auc

set.seed(123)
fit_glm <- train(GPA ~ ., method = "glm", trControl = train.control, data = x.c)
probs2 = predict(fit_glm, newdata = x.test.c, type = "prob")
R2 = roc(y.test.c, probs2[,2])
plot.roc(R2, col=1, lwd=2, add = TRUE)
AUC2 = R2$auc

fit_rf <- train(GPA ~ ., method = "rf", trControl = train.control, data = x.c)
probs3 = predict(fit_rf, newdata = x.test.c, type = "prob")
R3 = roc(y.test.c, probs3[,2])
plot.roc(R3, add = TRUE, col=2, lwd=2)
AUC3 = R3$auc

fit_lda <- train(GPA ~ ., method = "lda", trControl = train.control, data = x.c)
probs4 = predict(fit_lda, newdata = x.test.c, type = "prob")
R4 = roc(y.test.c, probs4[,2])
plot.roc(R4, add = TRUE, col=3, lwd=2)
AUC4 = R4$auc


```

Generate ROC curves
```{r}
test <- data.frame(D = y.test.c, knn = probs1[,2], glm = probs2[,2], rf = probs3[,2], lda = probs4[,2])
head(test)
test <- test %>% tidyr::gather(key = Model, value = M, -D)
```

```{r}
ggplot(data = test, aes(d = D, m = M, color = Model, linetype = Model)) +
  geom_roc(n.cuts = 0) + 
  theme_bw() +
  ggtitle("ROC Curve for GPA Prediction")
```




```{r}
plot.roc(R1, col=1, lwd=2, main="ROC curves")
plot.roc(R2, add = TRUE, col=2, lwd=2)
plot.roc(R3, add = TRUE, col=3, lwd=2)
plot.roc(R4, add = TRUE, col=4, lwd=2)
```

```{r, fig.height=12}
set.seed(1234)
fit_rf <- train(GPA ~ ., method = "rf", trControl = train.control, data = x.c)
plot(varImp(fit_rf, scale = FALSE))
```

